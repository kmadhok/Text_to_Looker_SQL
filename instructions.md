PRODUCT REQUIREMENTS DOCUMENT â€“ GEMINI RAG PLAYGROUND

VERSION: 0.1â€ƒâ€ƒDATE: 19â€¯Junâ€¯2025
AUTHOR: ChatGPT draft for Kanu

PURPOSE & SCOPE

Build a selfâ€‘contained Retrievalâ€‘Augmented Generation (RAG) playground that:
â€¢ Works without Looker credentials by default (using a stub)
â€¢ Uses GoogleÂ Gemini for both text generation and embeddings
â€¢ Imitates the key Looker flow so that the real Looker SDK can be dropped in later with zero code changes
â€¢ Runs locally in <â€¯5â€¯minutes so it can be executed by a Cursor agent, a notebook, or a CI job

USERS & USEâ€‘CASES

U1Â (Data Engineer)â€ƒTests prompt design and JSONâ€‘schema validation offline.
U2Â (Analytics Engineer)â€ƒVerifies that a planned LookML model will answer plainâ€‘English questions before hitting production.
U3Â (LLM Engineer)â€ƒIntegrates the loop into a multistep agent (e.g. Crewâ€¯AI or Cursor agent) and later replaces the stub with the real Looker SDK.

FUNCTIONAL REQUIREMENTS

FRâ€‘1Â Generate a synthetic orders fact table with â‰¥1â€¯000 rows (numeric + dates).
FRâ€‘2Â Emit lightweight â€œfield documentsâ€ (one file per dimension/measure) for embedding.
FRâ€‘3Â Create a FAISS vector index using Gemini embeddings.
FRâ€‘4Â Accept a naturalâ€‘language question, retrieve topâ€‘k field docs, and ask Gemini to return a valid JSON WriteQuery object.
FRâ€‘5Â Execute the JSON query against the synthetic dataframe (or later the real Looker API) and return results.
FRâ€‘6Â Enforce a default row limit to avoid accidental large dumps.
FRâ€‘7Â All code runnable by:Â Â Â Â python make_synthetic_data.py â†’ python build_index.py â†’ python chat_gemini.py

NONâ€‘FUNCTIONAL REQUIREMENTS

NFRâ€‘1Â Localâ€‘only I/O except one outbound call to Gemini endpoints.
NFRâ€‘2Â Setup in <â€¯2â€¯min on a modern laptop (Mâ€‘series or x86).
NFRâ€‘3Â Roundâ€‘trip latency (retrieve âž” generate âž” execute) <â€¯1â€¯s for a 1â€¯000â€‘row dataset using geminiâ€‘2.5â€‘flash.
NFRâ€‘4Â All dependencies managed via pip; no Docker required.
NFRâ€‘5Â Source code must be plaintext so Cursor agent can parse/refactor.

SYSTEM DESIGN

COMPONENTS
Â· make_synthetic_data.pyâ€ƒCreates CSV and field docs â†’ fake_metadata.json
Â· fake_looker.pyâ€ƒMinimal stub exposing the three SDK methods our loop needs
Â· build_index.pyâ€ƒEmbeds docs with Geminiâ€‘embeddingâ€‘001 and saves FAISS index
Â· chat_gemini.pyâ€ƒEndâ€‘toâ€‘end RAG loop (retrieve â†’ Gemini Flash â†’ execute â†’ return)

DATA FLOW
1Â User question âž” chat_gemini.py
2Â Script pulls k nearest docs from FAISS.
3Â Docs + question âž” Gemini Flash âž” JSON WriteQuery.
4Â JSON âž” fake_looker.run_inline_query âž” pandas filter âž” rows.
5Â Rows printed / returned to agent.

SETUP & RUNBOOK

Prereqs: Pythonâ€¯â‰¥â€¯3.10, internet to reach api.gemini.

export GOOGLE_API_KEY="<yourâ€‘key>"

pip install -r requirements.txt (see below)

python make_synthetic_data.py

python build_index.py

python chat_gemini.py â€“ ask your first question.

requirements.txt

pandas
faiss-cpu
google-generativeai
llama-index
llama-index-embeddings-google-genai

FOLDER STRUCTURE (checked into repo root)

rag_playground/
â”œâ”€â”€ fake_looker.py
â”œâ”€â”€ make_synthetic_data.py
â”œâ”€â”€ build_index.py
â”œâ”€â”€ chat_gemini.py
â”œâ”€â”€ lookml_docs/                # autoâ€‘generated docs per field
â”œâ”€â”€ orders.csv                  # autoâ€‘generated fact table
â”œâ”€â”€ fake_metadata.json          # autoâ€‘generated LookML stub
â””â”€â”€ lookml_faiss/               # persisted FAISS index

FULL SOURCE LISTINGS

make_synthetic_data.py

import pandas as pd, random, pathlib, json, datetime as dt

BASE = pathlib.Path('.')
DOCS = BASE / 'lookml_docs'
DOCS.mkdir(exist_ok=True)

MODEL = 'ecommerce'
EXPLORE = 'orders'
fields = [
    {'name': 'orders.id',           'label': 'Order ID',      'type': 'dimension', 'sql': '${TABLE}.id'},
    {'name': 'orders.created_date', 'label': 'Created Date',  'type': 'dimension', 'sql': '${TABLE}.created_date'},
    {'name': 'orders.total_sale',   'label': 'Total Sale $',  'type': 'measure',   'sql': 'SUM(${TABLE}.sale)'},
]

meta = {'model': MODEL, 'explore': EXPLORE, 'fields': fields}
(BASE / 'fake_metadata.json').write_text(json.dumps(meta, indent=2))

for f in fields:
    text = f"{f['name']}\n{f['label']}\n{f['sql']}"
    (DOCS / f"{f['name']}.txt").write_text(text)

N = 1_000
today = dt.date.today()
data = {
    'id': range(1, N + 1),
    'created_date': [today - dt.timedelta(days=random.randint(0, 60)) for _ in range(N)],
    'sale': [round(random.uniform(20, 500), 2) for _ in range(N)],
}

pd.DataFrame(data).to_csv(BASE / 'orders.csv', index=False)
print('ðŸŸ¢  Synthetic data + metadata ready.')

fake_looker.py

import pandas as pd, json
_meta = json.loads(open('fake_metadata.json').read())
_df   = pd.read_csv('orders.csv', parse_dates=['created_date'])

def all_lookml_models(fields=None):
    return [{'name': _meta['model'], 'label': _meta['model'].title()}]

def lookml_model(model_name, fields=None):
    if model_name != _meta['model']:
        raise ValueError('unknown model')
    return {'name': model_name, 'explores': [{'name': _meta['explore'], 'label': _meta['explore'].title()}]}

def run_inline_query(result_format, query):
    if query['model'] != _meta['model'] or query['view'] != _meta['model']:
        raise ValueError('bad model/view')
    df = _df.copy()
    for key, val in (query.get('filters') or {}).items():
        if key == 'orders.created_date' and 'days' in val:
            days = int(val.split()[0])
            cutoff = _df['created_date'].max() - pd.Timedelta(days=days)
            df = df[df['created_date'] >= cutoff]
    if query.get('limit'):
        df = df.head(int(query['limit']))
    if result_format == 'json':
        cols = [c.split('.')[1] for c in query['fields']]
        return df[cols].to_json(orient='records')
    raise NotImplementedError

build_index.py (Gemini embeddings)

from llama_index import VectorStoreIndex, SimpleDirectoryReader
from llama_index.embeddings.google_genai import GoogleGenAIEmbedding

docs = SimpleDirectoryReader('lookml_docs').load_data()
index = VectorStoreIndex.from_documents(
    docs,
    embed_model=GoogleGenAIEmbedding(model_name='gemini-embedding-001'),
    show_progress=True
)
index.storage_context.persist('lookml_faiss')
print('ðŸŸ¢  Vector index built with Gemini embeddings.')

chat_gemini.py

import os, json, fake_looker as sdk
from llama_index import VectorStoreIndex
from google import generativeai as genai

os.environ['GOOGLE_API_KEY']  # ensure set externally
index = VectorStoreIndex.load_from_disk('lookml_faiss')
retriever = index.as_retriever(similarity_top_k=4)
client = genai.Client()
MODEL_ID = 'gemini-2.5-flash'

def ask(question: str, limit: int = 10):
    ctx = '\n\n'.join(n.node.get_content() for n in retriever.retrieve(question))
    prompt = f"""{ctx}\n\nUser: {question}\nReturn ONLY JSON with keys model, view, fields, filters, limit."""
    resp = client.models.generate_content(model=MODEL_ID, contents=prompt, stream=False)
    query = json.loads(resp.text.strip())
    query.setdefault('limit', limit)
    rows = json.loads(sdk.run_inline_query('json', query))
    return rows

if __name__ == '__main__':
    print(ask('show total_sale and id for the last 30 days limit 5'))

9.â€¯FUTURE ROADMAP

â€¢Â Swap fake_looker.py for from looker_sdk import init40 once credentials work.
â€¢Â Add Gemini functionâ€‘calling schema for strict JSON enforcement.
â€¢Â Implement streaming output for conversationâ€‘style UI.
â€¢Â Add integration test that validates JSON against pydantic model.

10.â€¯REFERENCES

Gemini docsâ€ƒhttps://ai.google.devFAISSâ€ƒhttps://github.com/facebookresearch/faissLlamaâ€‘Indexâ€ƒhttps://github.com/run-llama/llama_index

===Â ENDÂ OFÂ DOCUMENTÂ ===